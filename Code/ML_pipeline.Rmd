---
title: "ML_Trial"
author: "Andrea,Gloria,Lorenzo,Thomas"
date: "`r Sys.Date()`"
output: html_document
---
# Preparatory steps
  Loading packages
  Store package names in a vectors for ease of access and to load them easily 
```{r Setup, message=FALSE, warning=FALSE}

# Define a list of packages to be loaded
PACKAGES <- c(
  "randomForest",    # For random forest modeling
  "caret",           # For machine learning model training and evaluation
  "gmodels",         # Provides tools for model diagnostics
  "yardstick",       # For model evaluation metrics
  "ggplot2",         # For data visualization
  "corrplot",        # For correlation plot visualization
  "tidyverse",       # Collection of packages for data manipulation and visualization
  "factoextra",      # Additional tools for clustering and factor analysis
  "FactoMineR",      # For exploratory data analysis and multivariate analysis
  "glue",            # For string interpolation
  "plotly",          # Interactive plots
  "dplyr",           # To manage data frames more efficiently
  "kernlab",         # Kernel-based machine learning methods
  "readr",           # For reading and parsing data
  "e1071",           # For SVM modeling and much MORE!
  "class",           # Various classification methods
  "MASS",            # Modern Applied Statistics with S
  "glmnet",          # For the LASSO regression 
  "class",           # For the KNN method
  "xgboost"          # For the XGBoost (Extreme Gradient Boosting) method
  
)

# Load the specified packages
invisible(lapply(PACKAGES, library, character.only = TRUE))


```

## Managing the data to use

```{r Data to use, warning=FALSE}
# Load the data
setwd("D:/VarieTHOM/University/QCB/3_SEMESTRE/Data Mining/Laboratory (Blanzieri)/0_PROJECT/Datasets_finals")
ML_data <- data.frame(read_csv("ML_data.csv", col_names = TRUE))

# Set rownames
ML_data <- subset(ML_data, select = -((ncol(ML_data) - 4):ncol(ML_data)))
row.names(ML_data) <- ML_data$...1

# Eliminate the columns that are not needed
my_data <- subset(ML_data, select = -c(...1,risk...127))
#my_data$risk...127 <- NULL

# Subset data frame by condition
#df_Tumor <- subset(my_data, C_T...125 == "Tumor")
```

## Number coating

```{r Current otimal way  }
# Getting ready to do predictions
# Number coating the values
## Specify the columns to be label encoded
columns_to_encode <- c("type...126", "C_T...125", "Cell_type...128")
columns_to_encode2 <- c("type...126", "C_T...125")

# Create a new data frame without rows where 'Cell_type...128' has value "Unknown"
my_data_train <- subset(my_data, Cell_type...128 != "Unkown")

# Convert specified columns to factor type
my_data_train <- my_data_train %>% mutate_at(columns_to_encode, as.factor)

# Display levels of 'Cell_type...128'
levels(my_data_train$Cell_type...128)

# Convert specified columns to factor type for the entire dataset
my_data_encoded <- my_data %>% mutate_at(columns_to_encode, as.factor)


# Do the number coating as numbers
encoded <- my_data_encoded %>% mutate_at(columns_to_encode, as.numeric)
train_data <- my_data_train %>% mutate_at(columns_to_encode, as.numeric)

# Create a dictionary-like structure to store the labels
## The order corresponds to the number
my_levels <- list(
  type...126 = levels(my_data_encoded$type...126),
  C_T...125 = levels(my_data_encoded$C_T...125),
  Cell_type...128 = levels(my_data_encoded$Cell_type...128)
)



```

# Split the data sets to start the following analysis

```{r Split the data}

# Set the seed for reproducibility
#set.seed(1234)

# Create an index for splitting the data
index <- createDataPartition(my_data_train$Cell_type...128, p = 0.7, list = FALSE)

# Create the training set
train <- my_data_train[index, ]
train_lda <- train[, -124]

# Create the testing set
test <- my_data_train[-index, ]

# Create an index for splitting the data
index_numeric <- createDataPartition(train_data$Cell_type...128, p = 0.7, list = FALSE)

# Create the numeric training set
train_n <- train_data[index_numeric, ]

# Create the numeric testing set
test_n <- train_data[-index_numeric, ]


"# Use 70% of the dataset as the training set and the remaining 30% as the testing set
# Create a logical vector for sampling with replacement
sample <- sample(c(TRUE, FALSE), nrow(my_data_train), replace = TRUE, prob = c(0.7, 0.3))

# Create the training set
train <- my_data_train[sample, ]
train_lda <- train[, -124]

# Create the testing set
test <- my_data_train[!sample, ]

# Create a logical vector for sampling without replacement for numeric data
sample_numeric <- sample(c(TRUE, FALSE), nrow(train_data), replace = TRUE, prob = c(0.7, 0.3))

# Create the numeric training set
train_n <- train_data[sample, ]

# Create the numeric testing set
test_n <- train_data[!sample, ]"

```

# Random Forest:

  -Type: Supervised Learning (Classification or Regression)
  
  -Description: Random Forest is an ensemble learning method that constructs a multitude of decision trees during training and outputs the mode of         the classes (classification) or the mean prediction (regression) of the individual trees. It is known for its robustness and ability to handle       complex data.
  -Working:
    Random Forest builds multiple decision trees during training, each based on a random subset of the features and a random subset of the training      data.
    Each tree "votes" on the class for a given input, and the mode (classification) or average (regression) of these votes becomes the final             prediction.
    This ensemble approach often leads to improved generalization and robustness compared to individual decision trees.

```{r Optimise the RF}
# Set seed for reproducibility
set.seed(1235)

# Tune the Random Forest model
model_tuned <- tuneRF(
               x = my_data_train,                   # Define predictor variables
               y = my_data_train$Cell_type...128,  # Define response variable
               ntreeTry = 800,                      # Number of trees to try
               mtryStart = 4,                       # Starting value for mtry (number of variables randomly sampled as candidates at each split)
               stepFactor = 1.5,                    # Factor by which mtry is multiplied in each iteration
               improve = 0.01,                      # Minimum improvement in node impurity for a split to occur
               trace = FALSE,                       # Don't show real-time progress
               plot = TRUE,                         # Plot error rates during tuning
               importance = TRUE                   # Calculate variable importance
               )

```

# Fit the Random Forest model

```{r Fit the Random Forest model}
# Fit the Random Forest model
set.seed(1234)
model_RF <- randomForest(Cell_type...128 ~ ., 
                      data = train,
                      ntree = 800,
                      importance = TRUE,
                      mtry = 9
)

# Create a copy of the data for predictions
predicted_RF <- my_data_encoded

# Make predictions on the test set
test_RF <- predict(model_RF, newdata = test)

# Fit another Random Forest model on the entire training dataset
model_RF2 <- randomForest(Cell_type...128 ~ ., 
                      data = my_data_train,
                      ntree = 800,
                      importance = TRUE,
                      mtry = 9
)

# Make predictions on the new data
Prediction_RF <- predict(model_RF2, newdata = predicted_RF)

# View predictions
predict_RF <- data.frame(Prediction_RF)
predicted_RF$predicted_rf <- predict_RF$Prediction_RF
setwd("D:/VarieTHOM/University/QCB/3_SEMESTRE/Data Mining/Laboratory (Blanzieri)/0_PROJECT/Datasets_finals")
write.csv(predicted_RF, "Predict_rf.csv", row.names = TRUE)

# Display the predictions
predicted_RF

# Display fitted models
print(model_RF)   # Using print for a more informative display
print(model_RF2)

```

# First basic plots for RF

```{r Plots and metrics for RF, warning=FALSE}

# Find RMSE of the best model
# sqrt(model$mse[best_trees])  # Uncomment if you need to print the RMSE, works only on fully numbers

# Plot the test MSE by the number of trees
plot(model_RF2, main = "Test MSE by Number of Trees", type = "l", pch = 16)

# Produce a variable importance plot
varImpPlot(model_RF2, main = "Variable Importance Plot", col = "darkgreen")

# Partial dependence plots illustrate the relationship between a specific feature and the predicted outcome while holding other features constant.
# They are useful for understanding the effect of individual features on the model predictions.
partialPlot(model_RF2, train, PC3, col = "darkgreen", )

# Evaluate accuracy
# correct_predictions <- sum(test_RF == test$Cell_type...128)
# accuracy <- correct_predictions / nrow(test)

# Create a confusion matrix
conf_matrix <- table(test_RF, test$Cell_type...128)
#conf_matrix

cm <- confusionMatrix(test_RF, test$Cell_type...128)
cm

# Calculate metrics
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f1_score <- 2 * (precision * recall) / (precision + recall)

# Print the metrics
cat("\n","Accuracy:", accuracy, "\n")
cat("Precision:", mean(precision, na.rm = TRUE), "\n")
cat("Recall:", mean(recall, na.rm = TRUE), "\n")
cat("F1 Score:", mean(f1_score, na.rm = TRUE), "\n")

# Create a bar plot for precision, recall, and F1 score
metrics_df_RF <- data.frame(Metric = c("Precision", "Recall", "F1 Score"),
                         Value = c(mean(precision, na.rm = TRUE),
                                   mean(recall, na.rm = TRUE),
                                   mean(f1_score, na.rm = TRUE)))

metrics_df_RF

```

## K-Nearest Neighbors (KNN) Model:

  -Type: Supervised Learning (Classification or Regression)
  -Description: KNN is a simple algorithm that classifies a new data point based on the majority class of its k-nearest neighbors in the feature         space. It is a non-parametric, instance-based learning algorithm.
  
  -Working:
    KNN classifies a data point based on the class labels of its k-nearest neighbors in the feature space.
    The distance metric (usually Euclidean distance) is used to measure the proximity between data points.
    The algorithm then assigns the majority class among the k-nearest neighbors to the new data point.

```{r K-Nearest Neighbors with class library training}
# Separate features and labels
train_features <- train_n[, -ncol(train)]  # All columns except the last one
train_labels <- train_n$Cell_type...128    # The last column

# Fit the KNN model
k_value <- 4  # You can choose the value of k
knn_model <- knn(train_features, test_n[, -which(names(test_n) == "Cell_type...128")], train_labels, k = k_value)
```


```{r Plots and metrix for K-Nearest Neighbors}
# Confusion Matrix
conf_matrix <- table(Actual = test_n$Cell_type...128, Predicted = knn_model)
conf_matrix

# Calculate metrics from the confusion matrix
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f1_score <- 2 * (precision * recall) / (precision + recall)

# Print the metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision:", mean(precision, na.rm = TRUE), "\n")
cat("Recall:", mean(recall, na.rm = TRUE), "\n")
cat("F1 Score:", mean(f1_score, na.rm = TRUE), "\n")

# Create a data frame for precision, recall, and F1 score
metrics_df_KNN <- data.frame(Metric = c("Precision", "Recall", "F1 Score"),
                         Value = c(mean(precision, na.rm = TRUE),
                                   mean(recall, na.rm = TRUE),
                                   mean(f1_score, na.rm = TRUE)))
metrics_df_KNN


```

```{r K-Nearest Neighbors prediction}
# Separate features and labels
train_features <- train_data[, -ncol(train_data)]  # All columns except the last one
train_labels <- train_data$Cell_type...128    # The last column

# Fit the KNN model
k_value <- 4  # You can choose the value of k
knn_model <- knn(train_features, encoded[, -which(names(encoded) == "Cell_type...128")], train_labels, k = k_value)

# Create a data frame with KNN predictions
predictions_knn <- data.frame(as.numeric(knn_model))

# Rename the columns for clarity
predictions_knn$knn_model <- predictions_knn$as.numeric.knn_model.
predictions_knn$as.numeric.knn_model. <- NULL

# Combine the KNN predictions with the original encoded data
predicted_KNN <- encoded
predicted_KNN$predicted_Knn <- predictions_knn

#Write the results
setwd("D:/VarieTHOM/University/QCB/3_SEMESTRE/Data Mining/Laboratory (Blanzieri)/0_PROJECT/Datasets_finals")
write.csv(predicted_KNN, "Predict_Knn.csv", row.names = TRUE)
```


#Linear Discriminant Analysis (LDA):

  -Type: Supervised Learning (classification)
  -Description: LDA is a classification and dimensionality reduction technique that seeks to find the linear combinations of features that best          separate different classes in the data.
  
  -Working: It calculates the means and variances of each class and then finds a linear combination of features that maximizes the ratio of the          between-class variance to the within-class variance. This linear combination is then used for classification.

```{r Linear Discriminant Analysis (LDA) appllication}

# Prepare data for LDA prediction
predict_LDA <- my_data_encoded

# Make this example reproducible
set.seed(1234)

# Fit LDA model
lda_model <- lda(Cell_type...128 ~ ., 
                 data = train_lda)

# Remove the 124th column as it is not informative
my_data_LDA <- my_data_train[,-124]
lda_model2 <- lda(Cell_type...128 ~ ., 
                  data = my_data_LDA)

# View model output
## Prior probabilities of group: Represent proportions of each Species in the training set.
## Group means: Display mean values for each predictor variable for each label.
## Coefficients of linear discriminant: Display linear combination of predictor variables used to form the decision rule of the LDA model.
plot(lda_model2)

# Extract LDA scores
lda_scores <- as.data.frame(predict(lda_model2)$x)

# Use LDA model to make predictions on the test data
## Returns a list with three variables: class, posterior probability, and linear discriminants
predicted_LDA <- predict(lda_model2, predict_LDA)

# Create a dataframe with the results
predicted_LDA <- data.frame(predicted_LDA)
# Insert results into the dataframe to compare
predict_LDA$predicted_LDA <- predicted_LDA$class
setwd("D:/VarieTHOM/University/QCB/3_SEMESTRE/Data Mining/Laboratory (Blanzieri)/0_PROJECT/Datasets_finals")
write.csv(predict_LDA, "Predict_lda.csv", row.names = TRUE)

# Predict using the LDA model on the test set
predict_LDA_train <- predict(lda_model, test)



```

# LDA Visulization

```{r Plots and metrics for LDA,warning=FALSE}

# View predicted class for the first six observations in the test set
head(predict_LDA_train$class)

# View posterior probabilities for the first six observations in the test set
head(predict_LDA_train$posterior)

# View linear discriminants for the first six observations in the test set
head(predict_LDA_train$x)

# Create a confusion matrix
conf_matrix <- table(predict_LDA_train$class, test_n$Cell_type...128)
conf_matrix


# Calculate metrics
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f1_score <- 2 * (precision * recall) / (precision + recall)

# Print the metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision:", mean(precision, na.rm = TRUE), "\n")
cat("Recall:", mean(recall, na.rm = TRUE), "\n")
cat("F1 Score:", mean(f1_score, na.rm = TRUE), "\n")

# Create a DF for precision, recall, and F1 score
metrics_df_LDA <- data.frame(Metric = c("Precision", "Recall", "F1 Score"),
                         Value = c(mean(precision, na.rm = TRUE),
                                   mean(recall, na.rm = TRUE),
                                   mean(f1_score, na.rm = TRUE)))
metrics_df_LDA


# Define data to plot
lda_plot <- cbind(my_data_LDA, predict(lda_model2)$x)

# Create ggplot2 2D scatter plot
ggplot(lda_plot, aes(LD1, LD2, color = Cell_type...128)) +
  geom_point() +
  ggtitle("LDA 2D Scatter Plot")

# Create plotly 2D scatter plot
plot_ly(lda_plot, x = ~LD1, y = ~LD2, color = ~Cell_type...128, type = "scatter", mode = "markers") %>%
  layout(title = "LDA 2D Scatter Plot")

# Create plotly 3D scatter plot
plot_ly(lda_plot, x = ~LD1, y = ~LD2, z = ~LD3, color = ~Cell_type...128, 
        type = "scatter3d", mode = "markers") %>%
  layout(scene = list(aspectmode = "cube")) %>%
  layout(title = "LDA 3D Scatter Plot")

```
 
 
# LASSO (Least Absolute Shrinkage and Selection Operator):

  -Type: Regularization technique for linear regression
  -Description: LASSO is a regression technique that introduces a penalty term to the linear regression objective function, encouraging the model to     use fewer features by driving some of their coefficients to zero.
  
  -Working: The penalty term is the absolute sum of the coefficients. It helps prevent overfitting and promotes sparsity in the model, making it         useful for feature selection.

```{r Find the optimal lambda}


# Create a matrix of predictors
X <- as.matrix(train_data[, -which(names(train_data) == "Cell_type...128")])


# Convert the response variable to a numeric vector
y <- as.numeric(train_data$Cell_type...128)

# Perform k-fold cross-validation to find the optimal lambda value
cv_model <- cv.glmnet(X, y, alpha = 1)

# Print the cross-validated results
print(cv_model)

# Find the optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda

# Produce a plot of test MSE by lambda value
plot(cv_model)
 
```

```{r LASSO appllication }
# Find coefficients of the best model
best_model <- glmnet(X, y, alpha = 1, lambda = best_lambda)
best_model1 <- glmnet(as.matrix(train_n[, -which(names(train_n) == "Cell_type...128")]), 
                      as.numeric(train_n$Cell_type...128), 
                      alpha = 1, 
                      lambda = best_lambda)

# Create a copy of the encoded data
predicted_LASSO <- as.matrix(encoded[, -which(names(encoded) == "Cell_type...128")])

#x_test <- as.matrix(test_n[, -which(names(train_n) == "Cell_type...128")])

# Use lasso regression model to predict the response value
matrix_predict1<- round(predict(best_model1, s = best_lambda, newx = as.matrix(test_n[, -which(names(test_n) == "Cell_type...128")])))
matrix_predict <- data.frame(round(predict(best_model, s = best_lambda, newx = predicted_LASSO)))

# Create a confusion matrix
conf_matrix <- table(matrix_predict1, test_n$Cell_type...128)
conf_matrix

# Calculate metrics
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f1_score <- 2 * (precision * recall) / (precision + recall)

# Print the metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision:", mean(precision, na.rm = TRUE), "\n")
cat("Recall:", mean(recall, na.rm = TRUE), "\n")
cat("F1 Score:", mean(f1_score, na.rm = TRUE), "\n")

# Add predicted values to the encoded_LS data frame
predicted_LASSO<- data.frame(predicted_LASSO)
predicted_LASSO$Cell_type...128 <- encoded$Cell_type...128
predicted_LASSO$Predict_LASSO <- matrix_predict$s1
predicted_LASSO
setwd("D:/VarieTHOM/University/QCB/3_SEMESTRE/Data Mining/Laboratory (Blanzieri)/0_PROJECT/Datasets_finals")
write.csv(predicted_LASSO, "Predict_lasso.csv", row.names = TRUE)

# Create a DF for precision, recall, and F1 score
metrics_df_LASSO <- data.frame(Metric = c("Precision", "Recall", "F1 Score"),
                         Value = c(mean(precision, na.rm = TRUE),
                                   mean(recall, na.rm = TRUE),
                                   mean(f1_score, na.rm = TRUE)))
metrics_df_LASSO
```

# Multiclass SVM [Doesnt work well :(... ]

```{r}
# Train the SVM model
svmfit <- svm(train_n, 
                 train_n$Cell_type...128, 
                 kernel = "radial")

# Print the summary of the model
print(svmfit)

# Extract predictors from the prediction data
x_predict <- encoded

# Make predictions
predictions <- round(predict(svm_model, x_predict))

preditions_train <- round(predict(svm_model, test_n))

# Create a confusion matrix
conf_matrix <- table(preditions_train, test_n$Cell_type...128)
conf_matrix
# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)

# Calculate metrics
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f1_score <- 2 * (precision * recall) / (precision + recall)

# Print the metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision:", mean(precision, na.rm = TRUE), "\n")
cat("Recall:", mean(recall, na.rm = TRUE), "\n")
cat("F1 Score:", mean(f1_score, na.rm = TRUE), "\n")

# Print accuracy
cat("Accuracy:", accuracy, "\n")

# Add the predictions to the prediction data frame
x_predict$predicted_class <- predictions

# View the updated prediction data frame
#print(x_predict)
```

# XGBoost (Extreme Gradient Boosting):

  -Type: Ensemble Learning (boosting method)
  -Description: XGBoost is a powerful and efficient implementation of gradient boosting. It sequentially adds weak learners (usually decision trees)     to the model, each correcting errors of the previous one.
  -Working: It optimizes a loss function and includes regularization terms to avoid overfitting. The final prediction is a weighted sum of the           predictions from all the weak learners.

```{r XGBoost (Extreme Gradient Boosting)}
library(xgboost)

# Step 1: Prepare the data
# Ensure that the last column in 'train_n' is the variable you want to predict
# For XGBoost, the response variable should be a factor for classification problems
# Extract predictor variables and response variable
X_train <- as.matrix(train_n[, -which(names(train_n) == "Cell_type...128")])  # Exclude the response variable
y_train <- as.matrix(train_n$Cell_type...128) -1   # Response variable

# Step 2: Train the XGBoost model
xgb_model <- xgboost(data = as.matrix(X_train), 
                     label = as.matrix(y_train), 
                     objective = "multi:softmax", 
                     num_class = 4,
                     nrounds =500)

# Step 3: Make predictions on the new data
X_predict <- test_n[, -ncol(test_n)]  # Exclude the response variable

# Predict the class labels 
predictions_xgb <- data.frame(predict(xgb_model, as.matrix(X_predict)) +1)

predictions_xgb$predicted_xgb<- predictions_xgb$predict.xgb_model..as.matrix.X_predict.....1

predictions_xgb$predict.xgb_model..as.matrix.X_predict.....1<-NULL

#print(xgb_model)
summary(xgb_model)
```

```{r Plots and metrix for the XGBoost (Extreme Gradient Boosting)}
# Create a confusion matrix
conf_matrix <- table(predictions_xgb$predicted_xgb, test_n$Cell_type...128)

# Calculate metrics
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f1_score <- 2 * (precision * recall) / (precision + recall)

# Print the metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision:", mean(precision, na.rm = TRUE), "\n")
cat("Recall:", mean(recall, na.rm = TRUE), "\n")
cat("F1 Score:", mean(f1_score, na.rm = TRUE), "\n")

# Create a bar plot for precision, recall, and F1 score
metrics_df_xgb <- data.frame(Metric = c("Precision", "Recall", "F1 Score"),
                         Value = c(mean(precision, na.rm = TRUE),
                                   mean(recall, na.rm = TRUE),
                                   mean(f1_score, na.rm = TRUE)))

metrics_df_xgb
```

```{r XGB model on the full training set to predict}

# Create a matrix of predictors
X <- as.matrix(train_data[, -which(names(train_data) == "Cell_type...128")])

# Convert the response variable to a numeric vector
y <- as.numeric(train_data$Cell_type...128)

Y_minusuno = as.matrix(train_data$Cell_type...128) -1

xgb_model2 <- xgboost(data = as.matrix(X), 
                     label = as.matrix(Y_minusuno), 
                     objective = "multi:softmax", 
                     num_class = 4,
                     nrounds =800)
print(xgb_model2)
summary(xgb_model2)

#  Make predictions on the new data
xgb_predict <- encoded[, -ncol(encoded)]  # Exclude the response variable

# Predict the class labels 
xgb_predictions <- data.frame(predict(xgb_model2, as.matrix(xgb_predict)) +1)

xgb_predictions$predicted_xgb<- xgb_predictions$predict.xgb_model2..as.matrix.xgb_predict.....1

xgb_predictions$predict.xgb_model2..as.matrix.xgb_predict.....1<-NULL

xgb_predict$Cell_type...128 <- encoded$Cell_type...128
xgb_predict$predicted_xgb<-xgb_predictions$predicted_xgb

setwd("D:/VarieTHOM/University/QCB/3_SEMESTRE/Data Mining/Laboratory (Blanzieri)/0_PROJECT/Datasets_finals")
write.csv(xgb_predict, "Predict_xgb.csv", row.names = TRUE)

```

# Naive Bayes:

  -Type: Supervised Learning (classification)
  -Description: Naive Bayes is a probabilistic classifier based on Bayes' theorem. It assumes that the features are conditionally independent given      the class label, which is a strong and often unrealistic assumption.
  -Working: It calculates the probability of each class given a set of features and selects the class with the highest probability as the predicted      class. Naive Bayes is computationally efficient and works well in practice, especially for text classification.

```{r Naive Bayes Model, warning=FALSE}
# Step 1: Prepare Data
features_train <- train[, -ncol(train)]
labels_train <- train[, ncol(train)]

features_predict <- test[, -ncol(test)]

Predict_nb <- my_data_encoded[, -ncol(my_data_encoded)]

# Step 2: Train Naive Bayes Model with Tuned Parameter
nb_model <- naiveBayes(features_train, labels_train, laplace = 0.001)

nb_model2 <- naiveBayes(train_data[, -ncol(train_data)], train_data[, ncol(train_data)], laplace = 0.001)

# Step 3: Make Predictions
predictions_nb <- predict(nb_model, features_predict)
predictions_nb2 <- data.frame(predict(nb_model, Predict_nb))

predictions_nb2$predicted_nb <- predictions_nb2$predict.nb_model..Predict_nb.
predictions_nb2$predict.nb_model..Predict_nb. <- NULL
Predict_nb$Cell_type...128 <- my_data_encoded$Cell_type...128
Predict_nb$predicted_nb <- predictions_nb2$predicted_nb
setwd("D:/VarieTHOM/University/QCB/3_SEMESTRE/Data Mining/Laboratory (Blanzieri)/0_PROJECT/Datasets_finals")
write.csv(Predict_nb, "Predict_nb.csv", row.names = TRUE)
```

```{r Plots and metrics for Naive Bayes}
# Create a confusion matrix
conf_matrix <- table(predictions_nb, test_n$Cell_type...128)
conf_matrix
# Calculate metrics
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
recall <- diag(conf_matrix) / colSums(conf_matrix)
f1_score <- 2 * (precision * recall) / (precision + recall)

# Print the metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision:", mean(precision, na.rm = TRUE), "\n")
cat("Recall:", mean(recall, na.rm = TRUE), "\n")
cat("F1 Score:", mean(f1_score, na.rm = TRUE), "\n")

# Create a DF for precision, recall, and F1 score
metrics_df_nb <- data.frame(Metric = c("Precision", "Recall", "F1 Score"),
                         Value = c(mean(precision, na.rm = TRUE),
                                   mean(recall, na.rm = TRUE),
                                   mean(f1_score, na.rm = TRUE)))
metrics_df_nb

```

